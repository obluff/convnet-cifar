{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os  \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches.meta  data_batch_2  data_batch_4  readme.html\n",
      "data_batch_1  data_batch_3  data_batch_5  test_batch\n"
     ]
    }
   ],
   "source": [
    "ls data/cifar-10-batches-py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(input_dir):\n",
    "    \"\"\"Takes in an input training directory and returns \n",
    "    \n",
    "        train_data, train_labels\n",
    "        test_data, test_labels\"\"\"\n",
    "    training_files = map(lambda x: import_image(''.join([input_dir, '/', 'data_batch_', str(x)])), range(2, 3))\n",
    "    \n",
    "    train_data, train_labels = reduce(lambda x, y: (np.append(x[0], y[0], axis=0), np.append(x[1], y[1], axis=0)), training_files)\n",
    "    test_data, test_labels = import_image('data/cifar-10-batches-py/test_batch')\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle_and_encode(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dic = pickle.load(fo, encoding='bytes')\n",
    "    return {str(k, 'utf-8'): v for k, v in dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_image(path):\n",
    "    raw_image_data = unpickle_and_encode(path)\n",
    "    \n",
    "    images, labels = raw_image_data['data'], raw_image_data['labels']\n",
    "    images = images.reshape((images.shape[0], 3, 32, 32)).transpose(0, 2, 3, 1) \n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_object, label = None):\n",
    "    \n",
    "    plt.title(label)\n",
    "    plt.imshow(img_object)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels = load_files('data/cifar-10-batches-py')\n",
    "label_encodings = unpickle_and_encode('data/cifar-10-batches-py/batches.meta')['label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(train_data[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VanillaCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VanillaCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "def loss_and_optimizer(net, learning_rate):\n",
    "    \n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_loader(batch_size, train_data, train_labels):\n",
    "    \n",
    "    dataset = TensorDataset(torch.Tensor(train_data.transpose(0,3,1,2)),\n",
    "                            torch.LongTensor(train_labels))\n",
    "    if batch_size is None:\n",
    "        return dataset\n",
    "    \n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                        num_workers=2)\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, batch_size, n_epochs, learning_rate, train_data, train_labels):\n",
    "    running_losses = []\n",
    "    train_loader = get_train_loader(batch_size, train_data, train_labels)\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    loss, optimizer = loss_and_optimizer(net, learning_rate)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            \n",
    "            inputs, labels = data\n",
    "           # inputs, labels = Variable(inputs), Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss_size = loss(outputs, labels)\n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            running_loss += loss_size.data.item()\n",
    "            total_train_loss += loss_size.data.item()\n",
    "\n",
    "            if i % 500 == 499: \n",
    "                print(\"Epoch {1}, \\n \\\n",
    "                       Train Loss: {2}\", i, running_loss/2500)\n",
    "                \n",
    "                running_losses += [running_loss]\n",
    "                running_loss = 0\n",
    "    return running_losses\n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.4585096549034119\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.42525071015357974\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.4057053865909576\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.38465723707675936\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.37511503670215607\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.3715015186071396\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.36275870168209073\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.34989271039962766\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.3467260493516922\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.3453192063808441\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.33910180087089536\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.3298230075955391\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.32780026886463165\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.32559932992458346\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.32093033030033113\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.3126304137587547\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.3128695985555649\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.30975919275283814\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.3053651390194893\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.29727070486545565\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.2978172850251198\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.29358374570608137\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.29013020485639573\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.2828487119734287\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.28345443766117095\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.27875056800842285\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.2746872809410095\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.2681419996619225\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.26898390934467314\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.26437374219298365\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.2588350371003151\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.25273227446079255\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.25517120819687844\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.25035797511339186\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.24496818732619285\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.23748454263210297\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.24059977334737778\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.23563173413276672\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.2303436635375023\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.22289479762017728\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.22410350814461708\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.22353820690214635\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.21851544697880745\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.20671774845719337\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.21203831470906734\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.2074779422402382\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.20346241226196288\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.19349148645401001\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.19867388621270657\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.19762459198832513\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.18940152802169322\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.17545365142822267\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.1873949871599674\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.18059378438591958\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.1778628361865878\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.16602193499207496\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.17647049103677273\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.1709719292715192\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.1660110213264823\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.15603218973726035\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.16096539824157954\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.1576785391405225\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.16231377160102128\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.1543267298579216\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.15099364086538553\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.1544364354431629\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.1496794098868966\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.1428304507032037\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.14398809671252966\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.1493937175653875\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.14115723006874323\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.13747432223185896\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.13525512194260955\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.12633242009803652\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.1431147173024714\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.13641009827814995\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.13740372586846353\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.12872465508058667\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.14735068249031902\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.137797238945961\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.12430726974233985\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.12743629761058836\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.1254182484181598\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1999 0.12567440238110722\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 499 0.12146677576899528\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 999 0.13172220978438853\n",
      "Epoch {1}, \n",
      "                        Train Loss: {2} 1499 0.12636016129981725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "gangsta = VanillaCNN()\n",
    "losses = train_model(gangsta, 5, 50, .001, train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "newnew = get_train_loader(None, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "new = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcifar-10-batches-py\u001b[0m/  \u001b[01;31minput_data.tar.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
       "          [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
       "          [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
       "          ...,\n",
       "          [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
       "          [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
       "          [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
       " \n",
       "         [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
       "          [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
       "          [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
       "          ...,\n",
       "          [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
       "          [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
       "          [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
       " \n",
       "         [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
       "          [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
       "          [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
       "          ...,\n",
       "          [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
       "          [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
       "          [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]]), 6)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3, 32, 32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.transpose(0, 3, 1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
